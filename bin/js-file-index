#!/usr/bin/env python
import os
import hashlib
import yaml
import argparse
from datetime import datetime
import logging
from typing import Any

logger = logging.getLogger(__name__)

def calculate_sha256(file_path: str) -> str:
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def get_file_info(file_path: str) -> dict[str, Any]:
    file_stats = os.stat(file_path)
    return {
        'file': os.path.basename(file_path),
        'folder': os.path.dirname(file_path),
        'sha256_hash': calculate_sha256(file_path),
        'date_last_modified': datetime.fromtimestamp(file_stats.st_mtime).isoformat(),
        'date_created': datetime.fromtimestamp(file_stats.st_ctime).isoformat()
    }

def load_existing_index(file_path: str) -> list[dict[str, Any]]:
    if not os.path.exists(file_path):
        return []
    with open(file_path, 'r') as f:
        return yaml.safe_load(f) or []

def generate_hash_for_directory(directory_path: str) -> list[dict[str, Any]]:
    files_data = []
    for root, dirs, files in os.walk(directory_path):
        for file in files:
            logger.info("Looking at file {}".format(file))
            file_path = os.path.join(root, file)
            file_info = get_file_info(file_path)
            files_data.append(file_info)
    return files_data

def create_index(directory_to_scan: str, output_yaml_file: str) -> None:
    files_data = generate_hash_for_directory(directory_to_scan)
    with open(output_yaml_file, 'w') as yaml_file:
        yaml.dump(files_data, yaml_file, default_flow_style=False)
    logger.info(f"File index created and saved in {output_yaml_file}")

def update_missing(directory_to_scan: str, output_yaml_file: str) -> None:
    existing_index = load_existing_index(output_yaml_file)
    existing_files = {file['file']: file for file in existing_index}

    new_files_data = []
    for root, dirs, files in os.walk(directory_to_scan):
        for file in files:
            if file not in existing_files:
                logger.info(f"Adding missing file {file}")
                file_path = os.path.join(root, file)
                file_info = get_file_info(file_path)
                new_files_data.append(file_info)

    if new_files_data:
        updated_data = existing_index + new_files_data
        with open(output_yaml_file, 'w') as yaml_file:
            yaml.dump(updated_data, yaml_file, default_flow_style=False)
        logger.info(f"Missing files added to index and saved in {output_yaml_file}")
    else:
        logger.info("No missing files found to add.")

def find_duplicate_hashes(output_yaml_file: str) -> None:
    existing_index = load_existing_index(output_yaml_file)
    hash_map = {}
    for file_info in existing_index:
        sha256_hash = file_info['sha256_hash']
        if sha256_hash in hash_map:
            hash_map[sha256_hash].append(file_info['folder'] + "/" + file_info['file'])
        else:
            hash_map[sha256_hash] = [file_info['folder'] + "/" + file_info['file']]

    duplicates_found = False
    for sha256_hash, paths in hash_map.items():
        if len(paths) > 1:
            duplicates_found = True
            print(f"Hash: {sha256_hash}")
            for path in paths:
                print(f" -> {path}")
            print("")

    if not duplicates_found:
        print("No duplicate hashes found.")

def main():
    parser = argparse.ArgumentParser(description="Manage file index with hashes")
    parser.add_argument('--create-index', action='store_true', help="Re-create the file index")
    parser.add_argument('--update-missing', action='store_true', help="Add missing files to the index")
    parser.add_argument('--duplicate-hashes', action='store_true', help="Find duplicate file hashes and print them")

    args = parser.parse_args()

    logging.basicConfig(level=os.getenv("LOGLEVEL", "INFO"))
    directory_to_scan = os.getcwd()
    output_file = 'js_file_index.yml'

    if args.create_index:
        create_index(directory_to_scan, output_file)
    elif args.update_missing:
        update_missing(directory_to_scan, output_file)
    elif args.duplicate_hashes:
        find_duplicate_hashes(output_file)
    else:
        print("No action specified. Use --create-index, --update-missing, or --duplicate-hashes")

if __name__ == "__main__":
    main()
